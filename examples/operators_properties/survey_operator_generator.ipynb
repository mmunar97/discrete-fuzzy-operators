{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\t Computing all possible operators.: 4025724406278it [01:42, 39397623915.43it/s] \n"
     ]
    }
   ],
   "source": [
    "import numpy\n",
    "import time\n",
    "\n",
    "from discrete_fuzzy_operators.base.operators.binary_operators.discrete.suboperators.fuzzy_discrete_aggregation_operator import DiscreteAggregationBinaryOperator\n",
    "from tqdm.notebook import tqdm\n",
    "from typing import Dict, List, Tuple"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_row_compensation_space(previous_row: List,\n",
    "                                    admissible_range: Tuple[int, int],\n",
    "                                    max_vector_size: int,\n",
    "                                    row_position: int,\n",
    "                                    recursive_step: int = 0,\n",
    "                                    row_list: List = None) -> List[int]:\n",
    "    \"\"\"\n",
    "    A generator which builds are possible vectors of a certain size (max_vector_size) that are increasing, where its\n",
    "    entries are taken from a range (admissible_range, representing a discrete interval [a,b]) and component-wise are \n",
    "    bigger than a given vector (previous_row).\n",
    "\n",
    "    Args:\n",
    "        previous_row: A list of integers, representing the vector whose entries are the lower-bounds of the generated vectors.\n",
    "        admissible_range: A tuple of two integers, representing the interval from which the candidate values will be taken.\n",
    "        max_vector_size: An integer, representing the size of the vector to be generated.\n",
    "        recursive_step: An integer, representing the number of recursive calls. It is used as the stop criterion.\n",
    "        row_list: A list of integers, representing the generated vector.\n",
    "\n",
    "    Returns:\n",
    "        A list of integers, representing the vector with size max_vector_size and which entries are in increasing order.\n",
    "    \"\"\"\n",
    "    assert max_vector_size <= len(previous_row), \"Number of entries of the generated vector is greater than the size of the bound vector. Expected to be less than or equal to its size.\"\n",
    "    \n",
    "    min_value = admissible_range[0]\n",
    "    max_value = admissible_range[1]\n",
    "    \n",
    "    if row_list is None:\n",
    "        row_list = []\n",
    "\n",
    "    if recursive_step == max_vector_size:\n",
    "        yield row_list\n",
    "    else:\n",
    "        minimum_row_value = min_value\n",
    "\n",
    "        if len(previous_row) > 0:\n",
    "            minimum_row_value = max(min_value, previous_row[recursive_step])\n",
    "\n",
    "        for i in range(minimum_row_value, max_value + 1):\n",
    "            if min(recursive_step,row_position) <= i <= max(recursive_step,row_position):\n",
    "                new_row = row_list.copy()\n",
    "                new_row.append(i)\n",
    "                yield from generate_row_compensation_space(previous_row=previous_row,\n",
    "                                                           admissible_range=(i,max_value),\n",
    "                                                           max_vector_size=max_vector_size,\n",
    "                                                           row_position=row_position,\n",
    "                                                           recursive_step=recursive_step+1,\n",
    "                                                           row_list=new_row)\n",
    "            else:\n",
    "                continue\n",
    "                \n",
    "def generate_recursive_compensation_space(n: int, e: int, row: int, previous_rows: List):\n",
    "    if row == n:\n",
    "        yield previous_rows\n",
    "    else:\n",
    "        previous_boundary = previous_rows[len(previous_rows)-1]\n",
    "        for next_row in generate_row_compensation_space(previous_row=previous_boundary, \n",
    "                                                        admissible_range=(0,row+1), \n",
    "                                                        max_vector_size=e,\n",
    "                                                        row_position=row+1):\n",
    "            if (row+1) == n:\n",
    "                if next_row[0] == 0 or next_row[0] == n: #Every discrete uninorms satisfies that U(n,0)=0 or U(n,0)=n.\n",
    "                    next_iteration_rows = previous_rows.copy()\n",
    "                    next_iteration_rows.append(next_row)\n",
    "                    yield from generate_recursive_compensation_space(n=n, e=e, row=row+1, previous_rows=next_iteration_rows)\n",
    "                else:\n",
    "                    continue\n",
    "            else:\n",
    "                next_iteration_rows = previous_rows.copy()\n",
    "                next_iteration_rows.append(next_row)\n",
    "                yield from generate_recursive_compensation_space(n=n, e=e, row=row+1, previous_rows=next_iteration_rows)\n",
    "                \n",
    "def generate_compensation_spaces(n: int, e: int):\n",
    "    boundary = [i for i in range(0, e)]\n",
    "    row = e+1\n",
    "    \n",
    "    for seed in generate_row_compensation_space(previous_row=boundary, \n",
    "                                                admissible_range=(0,row), \n",
    "                                                max_vector_size=e,\n",
    "                                                row_position=row):\n",
    "\n",
    "        for compensation_space in generate_recursive_compensation_space(n=n, e=e, row=row, previous_rows=[seed]):\n",
    "            yield numpy.flipud(numpy.array(compensation_space))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prova I\n",
    "\n",
    "Provam de generar tots els possibles espais de compensació i, com que coneixem el nombre de t-normes i t-conormes, podem intentar proposar una expressió."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_number_spaces(n: int, e: int):\n",
    "    number_spaces_n = 0\n",
    "    for e in range(1, (n-1)+1):\n",
    "        for space in generate_compensation_spaces(n=n, e=e):\n",
    "            number_spaces_n += 1\n",
    "    return number_spaces_n\n",
    "\n",
    "number_tnorms = {1:1, 2:2, 3:6, 4:22, 5:94, 6:451, 7:2386, 8:13775, 9:86417, 10:590489, 11:4446029, 12:37869449, 13:382549464}\n",
    "number_uninorms = {}\n",
    "\n",
    "for n in range(2,6+1):\n",
    "    uni = 2*number_tnorms[n]\n",
    "    \n",
    "    for e in range(1,(n-1)+1):\n",
    "        uni += number_tnorms[e]*number_tnorms[n-e]*get_number_spaces(n=n, e=e)\n",
    "    number_uninorms[n] = uni\n",
    "    \n",
    "print(number_uninorms)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Provem-ho amb un valor concret, amb $n=3$, per veure si la prova anterior és correcta."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from discrete_fuzzy_operators.base.operators.binary_operators.discrete.suboperators.fuzzy_discrete_aggregation_operator import DiscreteAggregationBinaryOperator\n",
    "\n",
    "template = numpy.array([[0,0,0,0], [0,1,2,3], [0,2,0,3], [0,3,3,3]])\n",
    "\n",
    "num = 0\n",
    "for x1 in range(0, 2+1):\n",
    "    for x2 in range(x1, 3+1):\n",
    "        for x3 in range(2,3+1):\n",
    "            another = template.copy()\n",
    "            another[0,2] = x1\n",
    "            another[2,0] = x1\n",
    "            another[0,3] = x2\n",
    "            another[3,0] = x2\n",
    "            another[2,2] = x3\n",
    "            \n",
    "            operator = DiscreteAggregationBinaryOperator(n=3, operator_matrix=another)\n",
    "            if operator.is_associative():\n",
    "                num += 1\n",
    "print(num)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "template = numpy.array([[0,0,0,0], [0,0,1,0], [0,1,2,3], [0,0,3,3]])\n",
    "\n",
    "num = 0\n",
    "for x1 in range(0, 1+1):\n",
    "    for x2 in range(0, 3+1):\n",
    "        for x3 in range(max(1,x2), 3+1):\n",
    "            another = template.copy()\n",
    "            another[1,1] = x1\n",
    "            another[0,3] = x2\n",
    "            another[3,0] = x2\n",
    "            another[1,3] = x3\n",
    "            another[3,1] = x3\n",
    "            \n",
    "            operator = DiscreteAggregationBinaryOperator(n=3, operator_matrix=another)\n",
    "            if operator.is_associative():\n",
    "                print(numpy.flipud(another))\n",
    "                num += 1\n",
    "print(num)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sembla que no és correcte. Per aquest valor concret, tenim $6+5+5+6=22$ uninormes possibles a $L_3$, mentres que amb la prova anterior ha sortit $84$. Com que al primer experiment no es comprova l'associativitat, segurament aquest és el motiu pel qual surten valors tan grans. A la següent prova, generem-les totes i mirem si són operadors associatius."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prova II"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "discrete_dataset_path = r\"C:\\Users\\Usuario\\OneDrive - Universitat de les Illes Balears\\UIB\\Tesi\\Experiments\\DiscreteDataset\"\n",
    "\n",
    "available_tnorms = {}\n",
    "available_tconorms = {}\n",
    "\n",
    "for n in range(1, 8+1):\n",
    "    available_tnorms[n]   = numpy.load(discrete_dataset_path+rf\"\\N={n}\\tnorms.npy\", allow_pickle=True)\n",
    "    available_tconorms[n] = numpy.load(discrete_dataset_path+rf\"\\N={n}\\tconorms.npy\", allow_pickle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_associativitiy(operator: numpy.ndarray, n: int) -> bool:\n",
    "    for x in range(0, n+1):\n",
    "        for y in range(0, n+1):\n",
    "            for z in range(0, n+1):\n",
    "                v1 = operator[y,z]\n",
    "                v2 = operator[x,y]\n",
    "                \n",
    "                if operator[x, v1] != operator[v2, z]:\n",
    "                    return False\n",
    "    return True\n",
    "\n",
    "def generate_uninorms(n: int, available_tnorms: Dict[int, List[numpy.array]], available_tconorms: Dict[int, List[numpy.array]], verbose: bool = False) -> Tuple[List[numpy.array], float]:\n",
    "    verboseprint = print if verbose else lambda *a, **k: None\n",
    "    \n",
    "    available_uninorms = []\n",
    "    start_time = time.time()\n",
    "\n",
    "    for e in range(0, n+1):\n",
    "        num_e = 0\n",
    "        if e == 0:\n",
    "            verboseprint(f\"---------- WORKING WITH e={e} ----------\")\n",
    "            verboseprint(len(list(available_tnorms[n])))\n",
    "            available_uninorms = available_uninorms+list(available_tnorms[n])\n",
    "        elif e == n:\n",
    "            verboseprint(f\"---------- WORKING WITH e={e} ----------\")\n",
    "            verboseprint(len(list(available_tconorms[n])))\n",
    "            available_uninorms = available_uninorms+list(available_tconorms[n])\n",
    "        else:\n",
    "            verboseprint(f\"---------- WORKING WITH e={e} ----------\")\n",
    "            for underlying_tnorm in available_tnorms[e]:\n",
    "                for underlying_tconorm in available_tconorms[n-e]:\n",
    "                    for compensation_space in generate_compensation_spaces(n=n, e=e):\n",
    "\n",
    "                        compensation_space_mod = numpy.flipud(compensation_space)\n",
    "\n",
    "                        uninorm_candidate = (-1)*numpy.ones((n+1, n+1), dtype=int)\n",
    "                        uninorm_candidate[0:(e+1), 0:(e+1)] = underlying_tnorm\n",
    "                        uninorm_candidate[e:(n+1), e:(n+1)] = e+underlying_tconorm\n",
    "                        uninorm_candidate[(e+1):(n+1), 0:e] = compensation_space_mod\n",
    "                        uninorm_candidate[0:e, (e+1):(n+1)] = numpy.transpose(compensation_space_mod)\n",
    "\n",
    "                        operator = DiscreteAggregationBinaryOperator(n=n, operator_matrix=uninorm_candidate)\n",
    "                        if operator.is_associative():\n",
    "                            available_uninorms.append(uninorm_candidate)\n",
    "                            num_e += 1\n",
    "            verboseprint(num_e)\n",
    "    elapsed_time = time.time()-start_time\n",
    "    \n",
    "    return available_uninorms, elapsed_time\n",
    "\n",
    "def count_uninorms(n: int, available_tnorms: Dict[int, List[numpy.array]], available_tconorms: Dict[int, List[numpy.array]], verbose: bool = False) -> Tuple[List[numpy.array], float]:\n",
    "    verboseprint = print if verbose else lambda *a, **k: None\n",
    "    \n",
    "    available_uninorms = 0\n",
    "    start_time = time.time()\n",
    "    \n",
    "    if n%2 == 0:\n",
    "        for e in range(0, int(n/2+1)):\n",
    "            if e == 0:\n",
    "                verboseprint(f\"---------- WORKING WITH e={e} AND e={n} ----------\")\n",
    "                verboseprint(2*len(list(available_tnorms[n])))\n",
    "                available_uninorms = available_uninorms+2*len(list(available_tnorms[n]))\n",
    "            else:\n",
    "                available_uninorms_e = 0\n",
    "                factor = 2\n",
    "                if e == (int(n/2+1)-1):\n",
    "                    factor = 1\n",
    "                \n",
    "                verboseprint(f\"---------- WORKING WITH e={e} AND e={n-e} ----------\")\n",
    "                compensation_spaces = [space for space in generate_compensation_spaces(n=n, e=e)]\n",
    "                progress_bar = tqdm(desc=\"\\t Computing all possible operators.\", total=len(compensation_spaces)*len(available_tnorms[e]*len(available_tconorms[n-e])))\n",
    "                done_cases = 0\n",
    "                \n",
    "                for compensation_space in compensation_spaces:\n",
    "                    for underlying_tnorm in available_tnorms[e]:\n",
    "                        for underlying_tconorm in available_tconorms[n-e]:\n",
    "                            compensation_space_mod = numpy.flipud(compensation_space)\n",
    "\n",
    "                            uninorm_candidate = (-1)*numpy.ones((n+1, n+1), dtype=int)\n",
    "                            uninorm_candidate[0:(e+1), 0:(e+1)] = underlying_tnorm\n",
    "                            uninorm_candidate[e:(n+1), e:(n+1)] = e+underlying_tconorm\n",
    "                            uninorm_candidate[(e+1):(n+1), 0:e] = compensation_space_mod\n",
    "                            uninorm_candidate[0:e, (e+1):(n+1)] = numpy.transpose(compensation_space_mod)\n",
    "\n",
    "                            if check_associativitiy(operator=uninorm_candidate, n=n):\n",
    "                                available_uninorms_e += 1\n",
    "                            \n",
    "                            done_cases += 1\n",
    "                            progress_bar.update(1)\n",
    "                \n",
    "                progress_bar.close()\n",
    "                verboseprint(factor*available_uninorms_e)\n",
    "                available_uninorms += factor*available_uninorms_e\n",
    "    else:\n",
    "        for e in range(0, int((n+1)/2)):\n",
    "            if e == 0:\n",
    "                verboseprint(f\"---------- WORKING WITH e={e} AND e={n} ----------\")\n",
    "                verboseprint(2*len(list(available_tnorms[n])))\n",
    "                available_uninorms = available_uninorms+2*len(list(available_tnorms[n]))\n",
    "            else:\n",
    "                available_uninorms_e = 0\n",
    "                factor = 2\n",
    "                \n",
    "                verboseprint(f\"---------- WORKING WITH e={e} AND e={n-e} ----------\")\n",
    "                compensation_spaces = [space for space in generate_compensation_spaces(n=n, e=e)]\n",
    "                progress_bar = tqdm(desc=\"\\t Computing all possible operators.\", total=len(compensation_spaces)*len(available_tnorms[e]*len(available_tconorms[n-e])))\n",
    "                done_cases = 0\n",
    "                \n",
    "                for compensation_space in compensation_spaces:\n",
    "                    for underlying_tnorm in available_tnorms[e]:\n",
    "                        for underlying_tconorm in available_tconorms[n-e]:\n",
    "                            compensation_space_mod = numpy.flipud(compensation_space)\n",
    "\n",
    "                            uninorm_candidate = (-1)*numpy.ones((n+1, n+1), dtype=int)\n",
    "                            uninorm_candidate[0:(e+1), 0:(e+1)] = underlying_tnorm\n",
    "                            uninorm_candidate[e:(n+1), e:(n+1)] = e+underlying_tconorm\n",
    "                            uninorm_candidate[(e+1):(n+1), 0:e] = compensation_space_mod\n",
    "                            uninorm_candidate[0:e, (e+1):(n+1)] = numpy.transpose(compensation_space_mod)\n",
    "\n",
    "                            if check_associativitiy(operator=uninorm_candidate, n=n):\n",
    "                                available_uninorms_e += 1\n",
    "                                \n",
    "                            done_cases += 1\n",
    "                            progress_bar.update(1)\n",
    "                \n",
    "                progress_bar.close()\n",
    "                verboseprint(factor*available_uninorms_e)\n",
    "                available_uninorms += factor*available_uninorms_e\n",
    "    \n",
    "    elapsed_time = time.time()-start_time\n",
    "    \n",
    "    return available_uninorms, elapsed_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------- WORKING WITH e=0 ----------\n",
      "451\n",
      "---------- WORKING WITH e=1 ----------\n",
      "308\n",
      "---------- WORKING WITH e=2 ----------\n",
      "217\n",
      "---------- WORKING WITH e=3 ----------\n",
      "194\n",
      "---------- WORKING WITH e=4 ----------\n",
      "217\n",
      "---------- WORKING WITH e=5 ----------\n",
      "308\n",
      "---------- WORKING WITH e=6 ----------\n",
      "451\n",
      "2146\n",
      "228.85136103630066\n"
     ]
    }
   ],
   "source": [
    "uninorms3, time6 = generate_uninorms(n=6, available_tnorms=available_tnorms, available_tconorms=available_tconorms, verbose=True)\n",
    "print(len(uninorms3))\n",
    "print(time6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------- WORKING WITH e=0 AND e=6 ----------\n",
      "902\n",
      "---------- WORKING WITH e=1 AND e=5 ----------\n",
      "616\n",
      "---------- WORKING WITH e=2 AND e=4 ----------\n",
      "434\n",
      "---------- WORKING WITH e=3 AND e=3 ----------\n",
      "194\n",
      "2146\n",
      "16.159329652786255\n"
     ]
    }
   ],
   "source": [
    "uni6, time6 = count_uninorms(n=6, available_tnorms=available_tnorms, available_tconorms=available_tconorms, verbose=True)\n",
    "print(uni6)\n",
    "print(time6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------- WORKING WITH e=0 AND e=7 ----------\n",
      "4772\n",
      "---------- WORKING WITH e=1 AND e=6 ----------\n",
      "3076\n",
      "---------- WORKING WITH e=2 AND e=5 ----------\n",
      "2068\n",
      "---------- WORKING WITH e=3 AND e=4 ----------\n",
      "1718\n"
     ]
    }
   ],
   "source": [
    "uni7, time7 = count_uninorms(n=7, available_tnorms=available_tnorms, available_tconorms=available_tconorms, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11634\n",
      "93.15575742721558\n"
     ]
    }
   ],
   "source": [
    "print(uni7)\n",
    "print(time7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------- WORKING WITH e=0 AND e=8 ----------\n",
      "27550\n",
      "---------- WORKING WITH e=1 AND e=7 ----------\n",
      "16708\n",
      "---------- WORKING WITH e=2 AND e=6 ----------\n",
      "10774\n",
      "---------- WORKING WITH e=3 AND e=5 ----------\n",
      "8504\n",
      "---------- WORKING WITH e=4 AND e=4 ----------\n",
      "3936\n",
      "67472\n",
      "21002.47544813156\n"
     ]
    }
   ],
   "source": [
    "uni8, time8 = count_uninorms(n=8, available_tnorms=available_tnorms, available_tconorms=available_tconorms, verbose=True)\n",
    "print(uni8)\n",
    "print(time8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
